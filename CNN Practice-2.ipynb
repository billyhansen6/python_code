{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 10000 images - 5000 images of dogs and 5000 images of cats. There are 4000 images of dogs and 4000 images of cats in the training data. There are 1000 images of dogs and 1000 images of cats in the test data. The goal of this assignment is to build a CNN model that can differentiate between the iages of dogs and images of cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convolution - detect features using summation of element-wise matrix multiplication.\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64,64,3), activation = 'relu'))\n",
    "# 32 feature maps of size 3x3\n",
    "# Input shape is a 64X64 image in color.\n",
    "# Activation funtion to ensure non-linearity is the rectifier function \"relu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling - reduce size of feature maps by detecting important features and discarding unimportant features\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#Pooling size is a 2x2 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening - flatten all feature maps from pooling layer into one dimentional vector\n",
    "# This vector is used as the input layer of an ANN\n",
    "# Spacial Structure is preserved\n",
    "classifier.add(Flatten()) # This serves as the input layer of an ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Full Connection - create hidden layers of ANN.\n",
    "classifier.add(Dense(output_dim = 128, activation= 'relu')) # hidden layer - 128 output nodes\n",
    "classifier.add(Dense(output_dim = 1, activation= 'sigmoid')) # Sigmoid for binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Adam optimizer for stochastic gradient decent\n",
    "# Binary Cross Entropy for Binary Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CNN to Images with Image Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255, # rescaling pixel data to be between 0 and 1\n",
    "    shear_range=0.2, # apply random transvections\n",
    "    zoom_range=0.2, # random zooms to 20% of the image.\n",
    "    horizontal_flip=True) # horizontal_flips\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # Only need to normalize Test Data - no augmentation necessary\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/Users/sauce/Desktop/Courses/Deep_Learning_A_Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Section 8 - Building a CNN/Convolutional_Neural_Networks-2/dataset/training_set',\n",
    "                                                target_size = (64, 64),\n",
    "                                                batch_size = 32, # Size of batches of images for augmentation each round.\n",
    "                                                class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('/Users/sauce/Desktop/Courses/Deep_Learning_A_Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Section 8 - Building a CNN/Convolutional_Neural_Networks-2/dataset/test_set',\n",
    "                                           target_size= (64, 64),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = 'binary')\n",
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    samples_per_epoch=8000, # photos in the training set for each epoch\n",
    "    nb_epoch=25, # number of epochs to run\n",
    "    validation_data = test_set, \n",
    "    nb_val_samples=2000) # number of images in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 398s 2s/step - loss: 0.6501 - acc: 0.6168 - val_loss: 0.5912 - val_acc: 0.6960\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 429s 2s/step - loss: 0.6025 - acc: 0.6764 - val_loss: 0.5532 - val_acc: 0.7319\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 405s 2s/step - loss: 0.5582 - acc: 0.7100 - val_loss: 0.5971 - val_acc: 0.6801\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 382s 2s/step - loss: 0.5375 - acc: 0.7279 - val_loss: 0.5203 - val_acc: 0.7546\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 385s 2s/step - loss: 0.5098 - acc: 0.7490 - val_loss: 0.4980 - val_acc: 0.7576\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 400s 2s/step - loss: 0.4954 - acc: 0.7604 - val_loss: 0.4915 - val_acc: 0.7569\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 400s 2s/step - loss: 0.4761 - acc: 0.7706 - val_loss: 0.5166 - val_acc: 0.7406\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 371s 1s/step - loss: 0.4558 - acc: 0.7886 - val_loss: 0.4704 - val_acc: 0.7783\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 381s 2s/step - loss: 0.4509 - acc: 0.7865 - val_loss: 0.4573 - val_acc: 0.7870\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 347s 1s/step - loss: 0.4369 - acc: 0.7925 - val_loss: 0.4940 - val_acc: 0.7697\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 373s 1s/step - loss: 0.4181 - acc: 0.8031 - val_loss: 0.4918 - val_acc: 0.7735\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 372s 1s/step - loss: 0.4115 - acc: 0.8092 - val_loss: 0.5420 - val_acc: 0.7581\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 408s 2s/step - loss: 0.4039 - acc: 0.8140 - val_loss: 0.4726 - val_acc: 0.7872\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 379s 2s/step - loss: 0.3874 - acc: 0.8209 - val_loss: 0.4809 - val_acc: 0.7831\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 438s 2s/step - loss: 0.3757 - acc: 0.8339 - val_loss: 0.4473 - val_acc: 0.7994\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 452s 2s/step - loss: 0.3638 - acc: 0.8354 - val_loss: 0.4657 - val_acc: 0.7980\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 429s 2s/step - loss: 0.3626 - acc: 0.8399 - val_loss: 0.4580 - val_acc: 0.7876\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 412s 2s/step - loss: 0.3521 - acc: 0.8425 - val_loss: 0.4605 - val_acc: 0.8090\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 439s 2s/step - loss: 0.3372 - acc: 0.8506 - val_loss: 0.4770 - val_acc: 0.7894\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 424s 2s/step - loss: 0.3208 - acc: 0.8574 - val_loss: 0.4582 - val_acc: 0.7953\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 406s 2s/step - loss: 0.3024 - acc: 0.8705 - val_loss: 0.5312 - val_acc: 0.7959\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 426s 2s/step - loss: 0.2940 - acc: 0.8751 - val_loss: 0.5150 - val_acc: 0.7780\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 402s 2s/step - loss: 0.2800 - acc: 0.8805 - val_loss: 0.4920 - val_acc: 0.8079\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 454s 2s/step - loss: 0.2794 - acc: 0.8868 - val_loss: 0.5007 - val_acc: 0.7959\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 437s 2s/step - loss: 0.2639 - acc: 0.8925 - val_loss: 0.5282 - val_acc: 0.7937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10b5c8f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add another convolution layer\n",
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64,64,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten()) \n",
    "classifier.add(Dense(output_dim = 128, activation= 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation= 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/Users/sauce/Desktop/Courses/Deep_Learning_A_Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Section 8 - Building a CNN/Convolutional_Neural_Networks-2/dataset/training_set',\n",
    "                                                target_size = (64, 64),\n",
    "                                                batch_size = 32, \n",
    "                                                class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('/Users/sauce/Desktop/Courses/Deep_Learning_A_Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Section 8 - Building a CNN/Convolutional_Neural_Networks-2/dataset/test_set',\n",
    "                                           target_size= (64, 64),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = 'binary')\n",
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    samples_per_epoch=8000, \n",
    "    nb_epoch=25, \n",
    "    validation_data = test_set, \n",
    "    nb_val_samples=2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
